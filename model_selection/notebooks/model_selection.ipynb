{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduccion a la evaluacion y seleccion de modelos\n",
    "### Metodologías aplicables en aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "### Agenda\n",
    "\n",
    "1- Introducción\n",
    "\n",
    "* Asuntos de la comunidad\n",
    "* Recursos en Github (temas vistos previamente)\n",
    "    + Introducción al análisis exploratorio de datos\n",
    "    + Introducción a la programación estadística\n",
    "    + Introducción a la regresión\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "2- Conceptos fundamentales (spanglish!)\n",
    "\n",
    "* Learners\n",
    "* Classifiers, regressors & models\n",
    "* Parameters & _HYPERparameters_\n",
    "* Generalization\n",
    "    + Underfitting\n",
    "    + Overfitting\n",
    "* Etc... etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "3- Protocolos de aprendizaje\n",
    "\n",
    "* Train & Test\n",
    "* Train, validate, test\n",
    "* Cross-validation\n",
    "    + Nested cross-validation\n",
    "* Temas para una próxima ocasión\n",
    "    + Repeated cross-validation (RxK)\n",
    "    + Repeated nested cross-validation\n",
    "    + Basta de CV: other resampling techniques\n",
    "        - Bootstrap\n",
    "        - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Asuntos de la comunidad\n",
    "* [Nuestra Comunidad (Meetup)](https://www.meetup.com/Comunidad-de-Analitica-en-Santo-Domingo-R-Python/)  \n",
    "\n",
    "* [Votación: Temas de Interés en Ciencia de Datos con Python](https://www.meetup.com/Comunidad-de-Analitica-en-Santo-Domingo-R-Python/polls/1252269/)  \n",
    "\n",
    "* [Votación: Grupo de lectura](https://www.meetup.com/Comunidad-de-Analitica-en-Santo-Domingo-R-Python/polls/1260390/)\n",
    "\n",
    "* [Votación: Nombre para la comunidad](https://www.meetup.com/Comunidad-de-Analitica-en-Santo-Domingo-R-Python/polls/1261236/)\n",
    "<br>\n",
    "\n",
    "Somos muy _democráticos_!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Recursos en Github\n",
    "\n",
    "### Temas vistos previamente\n",
    "\n",
    "[Introducción al analisis exploratorio de datos](https://github.com/pyrdr/charlas/blob/master/intro_eda_python/intro_pypandas.ipynb)\n",
    "\n",
    "[Introducción a la programación estadística](https://github.com/pyrdr/charlas/blob/master/python_stat_prog/python_prog_stat.ipynb)\n",
    "\n",
    "[Aprendizaje Supervisado con Python: Regresión](https://github.com/pyrdr/charlas/blob/master/python_regression/python_regression.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conceptos fundamentales\n",
    "#### Definiciones no rigurosas (a 35,000 pies de altura)\n",
    "\n",
    "* Modelo (primer significado):<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;Mecanismo capaz de codificar conocimiento para solución de problemas. Tipicamente es una función compuesta de parametros, ej.: modelo de regresión linear ($y = \\beta X + \\epsilon$)<br><br>\n",
    "\n",
    "* Learner (algoritmo):<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;Algoritmo o metodo que toma como insumo datos y genera una _función o programa_ capaz de emitir predicciones.<br><br>\n",
    "\n",
    "* Aprendizaje (learning) o entrenamiento (training):<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;La ejecución concreta o combinación de un _learner_ con datos aplicables.<br><br>\n",
    "\n",
    "* Classifiers, regressors & _models_ (segundo significado):<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;Implementación concreta de una función o programa que toma como insumo datos y genera _predicciones_. Aquí y en muchas ocasiones encontrarán que el término _model_ se refiere a este concepto, el del resultado del _aprendizaje o entrenamiento_<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptos fundamentales\n",
    "#### Definiciones no rigurosas (a 35,000 pies de altura)\n",
    "\n",
    "* Cost/Utility/Loss function:<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;Función objetivo o de costo que juzga basado en los datos que tan bien se han ajustado los _parameters_ al problema especifico.<br><br>\n",
    "\n",
    "* Parameters:<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;Conjunto de elementos configurables/variables que un _learner_ ajusta durante su proceso de aprendizaje para producir un _clasificador o regresor_<br><br>\n",
    "\n",
    "* HYPERparameters:<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;Conjunto de elementos configurables del _learner_ que _no_ se ajustan durante el proceso de aprendizaje, sino que deben ser determinados \"manualmente\" por nosotros.<br><br>\n",
    "\n",
    "* Predictores (_features_):<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Subconjunto vertical de los datos (columnas) que caracterizan cada ejemplo/registro y que son utilizados como insumo para predecir/clasificar.<br><br>\n",
    "    \n",
    "* Etiquetas (_labels_):<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Subconjunto vertical de los datos (columnas) que queremos predecir.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Conceptos fundamentales\n",
    "#### Definiciones no rigurosas (a 35,000 pies de altura)\n",
    "\n",
    "* Generalization:<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;El objetivo último de que el _modelo_ aprendido tenga un buen rendimiento con datos desconocidos, es decir en la _vida real_. El \"buen rendimiento\" puede definirse con la misma _función de utilidad_ que se uso durante _aprendizaje_ o con otras _metricas_.<br><br>\n",
    "    \n",
    "* Metricas:<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Función que tipicamente toma como insumo los datos (_predictores_ y _etiquetas_) y valora el rendimiento del modelo, es decir que tanto se acercan las predicciones a la realidad.<br><br>\n",
    "\n",
    "* Ruído (Noise):<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Término genérico que agrupa varias fuentes de distorción no deseada en los datos. Puede ser error de medición (humano o del instrumento), error de recolección, y variabilidad en los datos debido a las simplificaciones que son parte del modelo (1era definicion) usado, entre otras posibles fuentes.<br><br>\n",
    "    \n",
    "* Señal:<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Todo lo que no es ruido. Estos dos términos se toman prestados del área de [procesamiento de señales](https://es.wikipedia.org/wiki/Procesamiento_de_se%C3%B1ales), pero su uso es menos estricto.<br><br>\n",
    "    \n",
    "* Outlier (valor atipico):<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Es una observación que es muy distinta a las demás. Podría ser _ruido_ o _señal_, es dificil saber de antemano. Su presencia debe ser considerada puesto que puede tener impacto en cualquier análisis.<br><br>\n",
    "    \n",
    "* Underfitting:<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;Cuando un _modelo_ no aprende como esperado de los datos y su rendimiento con los mismos datos con los que fue entrenado es \"decepcionante\".<br><br>\n",
    "\n",
    "* Overfitting:<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;Cuando un _modelo_ presenta muy buen rendimiento con los datos con los que fue entrenado (o validado) pero no así con datos no vistos previamente. Podrían escuchar decir que se aprendío del _ruido_ (algo indeseable).<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/under_overfitting.jpg\" alt=\"Drawing\" style=\"width: 640px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overfitting curve\n",
    "\n",
    "![](../images/under_overfitting_curve.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Protocolos de Aprendizaje\n",
    "\n",
    "Pasos realizados para construir modelos usando _learners_ y _datos_ de forma que se garantice:\n",
    "\n",
    "* Buen rendimiento (según la métrica elegida)\n",
    "* Poder obtener un _estimador no sesgado_ de la _generalización_. Es decir, una idea sincera de cómo funcionará nuestro modelo en la práctica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train & Test\n",
    "\n",
    "El protocolo más sencillo de todos\n",
    "\n",
    "![](../images/train-test.png)\n",
    "\n",
    "Dividimos los datos en dos partes. Entrenamos con una y estimamos la _generalizacion_ con la restante.\n",
    "\n",
    "Es la base de todos los demás y nos enseña el principio **_FUNDAMENTAL_**:<br>\n",
    "\n",
    "**&nbsp;&nbsp;&nbsp;&nbsp;Debemos estimar la _generalización_ siempre con datos que no hayan sido usados en lo absoluto**\n",
    "\n",
    "<br>\n",
    "_Cons_:\n",
    "* Solo tenemos un estimador punto de la generalización (un único valor)\n",
    "* Solo debemos ajustar los _parametros_ de **un** _modelo_. Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train, validate & Test\n",
    "\n",
    "![](../images/train-validate-test.png)\n",
    "\n",
    "Si nuestro _learner_ tiene _hyperparameters_ y queremos _optimizarlos_ debemos explorar diferentes valores/combinaciones.\n",
    "\n",
    "Dividir los datos en tres partes:\n",
    "* Train, para construir modelos con las diferentes configuraciónes de hyperparametros\n",
    "* Validate, para elegir el la configuración de hyperparametros que tiene mejor rendimiento\n",
    "* Test, para estimar la _generalización_ del modelo elegido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross-validation (CV)\n",
    "\n",
    "Empezamos a complicarnos para atacar la primera debilidad del protocolo _Train & Test_: que sólo tenemos un punto/valor estimado de la generalización (ej.: 95% casos bien clasificados). No sabemos qué tan preciso podría ser ese estimado.\n",
    "\n",
    "Quisieramos poder decir algo como: \"Clasificaremos correctamente entre 92% y 98% de los casos\"\n",
    "\n",
    "Para eso necesitamos _una distribución_ para el estimado de la generalización, es decir _varios_ valores con los cuales podamos calcular promedio, desviación estándar, etc.\n",
    "\n",
    "Así que:\n",
    "\n",
    "* dividimos los datos en K (2, 3, 4,...,K) partes\n",
    "* entrenamos con todas las partes excepto una\n",
    "* esa la reservamos para estimar la generalización\n",
    "* repetimos el proceso K veces, cambiando la parte con la cual estimamos\n",
    "* acumulamos todos los estimados en una _una muestra_ de la distribución de la generalización\n",
    "* tomamos el promedio como estimado final y lo calificamos con la desviación estandar de la muestra (como minimo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross-validation\n",
    "\n",
    "<img src=\"../images/cross_validation.png\" alt=\"Drawing\" style=\"width: 640px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Y qué de los _hyperparameters_\n",
    "\n",
    "Podemos usar _Cross-Validation_ tal cual lo acabamos de describir para de una misma vez:\n",
    "* escoger la mejor combinación de _hyperparameters_ de nuestro _learner_ \n",
    "* estimar la generalización del mejor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nested Cross-validation\n",
    "\n",
    "<img src=\"../images/nested_cv.png\" alt=\"Drawing\" style=\"width: 640px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nested Cross-validation (CV)\n",
    "\n",
    "Después de reenfocar la vista del mareo anterior, recordemos lo que estamos buscando:\n",
    "\n",
    "**Una estimación honesta de la generalización del modelo que finalmente usaremos en la práctica**\n",
    "\n",
    "Con lo que hemos considerado hasta ahora, para lograrlo debemos:\n",
    "\n",
    "1. Probar multiples combinaciones de _hyperparameters_ para los _datos_ que tenemos\n",
    "2. Elegir el \"mejor\" de los que vimos\n",
    "3. Estimar la generalización de este \"mejor\" modelo\n",
    "\n",
    "El nivel exterior de este protocolo nos dará una muestra de la distribución de la generalización, lo mismo que teníamos con el protocolo anterior.\n",
    "\n",
    "El nivel interior de CV en este protocolo nos permitirá probar múltiples combinaciones de _hyperparameters_ y elegir la que tenga el mejor rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un ejemplo\n",
    "con multiples oportunidades de mejora..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.special import boxcox1p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def transform(X):\n",
    "    \"\"\"Encapsular las transformaciones y limpiezas realizadas en charla previa\n",
    "\n",
    "    Asumiendo que X es un DataFrame y sin validación alguna\n",
    "\n",
    "    \"\"\"\n",
    "    X.drop(\"Id\", axis = 1, inplace = True)\n",
    "    # Eliminamos los outliers\n",
    "    X = X.drop(X[(X['GrLivArea']>4000) & (X['SalePrice']<300000)].index)\n",
    "    # Empleamos la función log1p de numpy para obtener el log(1+x) de todos los elementos de la variable objetivo\n",
    "    y = np.log1p(X[\"SalePrice\"])\n",
    "    # Eliminamos la variable a predecir\n",
    "    X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "    #\n",
    "    X[\"PoolQC\"] = X[\"PoolQC\"].fillna(\"None\")\n",
    "    #\n",
    "    X[\"MiscFeature\"] = X[\"MiscFeature\"].fillna(\"None\")\n",
    "    X[\"Alley\"] = X[\"Alley\"].fillna(\"None\")\n",
    "    X[\"Fence\"] = X[\"Fence\"].fillna(\"None\")\n",
    "    X[\"FireplaceQu\"] = X[\"FireplaceQu\"].fillna(\"None\")\n",
    "    #\n",
    "    for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
    "        X[col] = X[col].fillna('None')\n",
    "    # \n",
    "    # Agrupamos por vecindario y completamos los valores perdidos con la mediana de LotFrontage para todos los vecindarios\n",
    "    X[\"LotFrontage\"] = X.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
    "        lambda x: x.fillna(x.median()))\n",
    "    #\n",
    "    for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
    "        X[col] = X[col].fillna(0)\n",
    "    #    \n",
    "    for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "        X[col] = X[col].fillna(0)\n",
    "    #\n",
    "    for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "        X[col] = X[col].fillna('None')\n",
    "    #\n",
    "    X[\"MasVnrType\"] = X[\"MasVnrType\"].fillna(\"None\")\n",
    "    X[\"MasVnrArea\"] = X[\"MasVnrArea\"].fillna(0)\n",
    "    #\n",
    "    X['MSZoning'] = X['MSZoning'].fillna(X['MSZoning'].mode()[0])\n",
    "    X = X.drop(['Utilities'], axis=1)\n",
    "    X[\"Functional\"] = X[\"Functional\"].fillna(\"Typ\")\n",
    "    X['Electrical'] = X['Electrical'].fillna(X['Electrical'].mode()[0])\n",
    "    X['KitchenQual'] = X['KitchenQual'].fillna(X['KitchenQual'].mode()[0])\n",
    "    X['Exterior1st'] = X['Exterior1st'].fillna(X['Exterior1st'].mode()[0])\n",
    "    X['Exterior2nd'] = X['Exterior2nd'].fillna(X['Exterior2nd'].mode()[0])\n",
    "    X['SaleType'] = X['SaleType'].fillna(X['SaleType'].mode()[0])\n",
    "    X['MSSubClass'] = X['MSSubClass'].fillna(\"None\")\n",
    "    #\n",
    "    # MSSubClass = El tipo de edificios\n",
    "    X['MSSubClass'] = X['MSSubClass'].apply(str)\n",
    "    # OverallCond\n",
    "    X['OverallCond'] = X['OverallCond'].astype(str)\n",
    "    # Año y mes de venta.\n",
    "    X['YrSold'] = X['YrSold'].astype(str)\n",
    "    X['MoSold'] = X['MoSold'].astype(str)\n",
    "    #\n",
    "    cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "            'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "            'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "            'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "            'YrSold', 'MoSold')\n",
    "    # procesa columnas, applicando LabelEncoder a los atributos categóricos\n",
    "    for c in cols:\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(X[c].values)) \n",
    "        X[c] = lbl.transform(list(X[c].values))\n",
    "    #\n",
    "    # Adicionamos el total de pies cuadrados (TotalSF) de la vivienda\n",
    "    X['TotalSF'] = X['TotalBsmtSF'] + X['1stFlrSF'] + X['2ndFlrSF']\n",
    "    #\n",
    "    numeric_feats = X.dtypes[X.dtypes != \"object\"].index\n",
    "    # Verificamos el sesgo de todos los atributos numéricos\n",
    "    skewed_feats = X[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "    skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "    #\n",
    "    skewness = skewness[abs(skewness) > 0.75]\n",
    "    skewed_features = skewness.index\n",
    "    lam = 0.15\n",
    "    for feat in skewed_features:\n",
    "        X[feat] = boxcox1p(X[feat], lam)\n",
    "    #\n",
    "    X = pd.get_dummies(X)\n",
    "    #\n",
    "    return X.values, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = transform(train.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Score 0.914551 +/- 0.025956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.linear_model import ElasticNet\n",
    "#\n",
    "np.random.seed(42)\n",
    "#\n",
    "enet = ElasticNet()\n",
    "p_grid = {\"alpha\": np.logspace(-3,1,10),\n",
    "          \"l1_ratio\": [0.001, .01, .1, 0.25, 0.5],\n",
    "         \"max_iter\": [1000,5000],\n",
    "         \"normalize\": [True, False]}\n",
    "#\n",
    "inner_cv = KFold(n_splits=4, shuffle=True)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True)\n",
    "# \n",
    "clf = GridSearchCV(estimator=enet, param_grid=p_grid, cv=inner_cv, n_jobs=-1)\n",
    "#\n",
    "nested_score = cross_val_score(clf, X=X, y=y, cv=outer_cv)\n",
    "#\n",
    "print('Avg Score {:4f} +/- {:4f}'.format(nested_score.mean(),nested_score.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consideraciones/dudas adicionales para una próxima\n",
    "\n",
    "* Cómo elegir entre diferentes algoritmos (y sus respectivos _hyperparameters_)?\n",
    "* Cuál es el impacto de las manipulaciones previas que se hicieron a los datos? (función _transform_)?\n",
    "* Cuál es el impacto de ligeros cambios en los datos usados?\n",
    "    * Qué pasa si _barajamos_ los datos y realizamos el experimento nuevamente? Qué tanto cambia la métrica?\n",
    "* Sobre el código como tal: cómo sé cuales fueron los _hyperparameters_ exactos que me dieron el _mejor_ modelo?\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
